import streamlit as st
import data_loader, vector_store
import google.generativeai as genai
import os
from config import GEMINI_API_KEY, CHAT_MODEL
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Paragraph
from reportlab.lib.styles import getSampleStyleSheet

# Config
genai.configure(api_key=GEMINI_API_KEY)
st.set_page_config(page_title="Chat v·ªõi t√†i li·ªáu", layout="wide")

# T·∫°o th∆∞ m·ª•c l∆∞u file t·∫°m
TEMP_DIR = "temp_uploads"
os.makedirs(TEMP_DIR, exist_ok=True)

if "history" not in st.session_state:
    st.session_state.history = []
if "files" not in st.session_state:
    st.session_state.files = []
if "file_history" not in st.session_state:
    st.session_state.file_history = []   # ch·ªâ l∆∞u t√™n file

# ---------------- Sidebar ----------------
with st.sidebar:
    st.header("üìÇ T√†i li·ªáu c·ªßa b·∫°n")
    uploaded_file = st.file_uploader(
        "T·∫£i file (PDF, Word, Excel, ·∫¢nh)",
        type=["pdf", "docx", "xlsx", "png", "jpg", "jpeg"],
        accept_multiple_files=True
    )

    if uploaded_file:
        for file in uploaded_file:
            if file.name not in [f["name"] for f in st.session_state.files]:
                with st.status(f"‚è≥ ƒêang x·ª≠ l√Ω file: {file.name}", expanded=True) as status:
                    # L∆∞u file v√†o th∆∞ m·ª•c ri√™ng
                    temp_path = os.path.join(TEMP_DIR, file.name)
                    with open(temp_path, "wb") as f:
                        f.write(file.read())

                    # X·ª≠ l√Ω file
                    text = data_loader.load_file(temp_path)
                    chunks = vector_store.get_text_chunks(text)
                    db_path = vector_store.save_vector_store(chunks)

                    st.session_state.files.append({
                        "name": file.name,
                        "path": temp_path,
                        "text": text,
                        "db": vector_store.load_vector_store(db_path)
                    })

                    # Ghi v√†o l·ªãch s·ª≠
                    if file.name not in st.session_state.file_history:
                        st.session_state.file_history.append(file.name)

                    status.update(label=f"‚úÖ File ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω: {file.name}", state="complete")

        uploaded_file = None  # reset uploader tr√°nh load l·∫°i

    # Hi·ªÉn th·ªã l·ªãch s·ª≠ t·∫£i file (ch·ªâ t√™n + n√∫t x√≥a)
    if st.session_state.file_history:
        st.markdown("### üïë L·ªãch s·ª≠ t·∫£i file:")
        for i, fname in enumerate(st.session_state.file_history):
            col1, col2 = st.columns([4,1])
            with col1:
                st.markdown(f"- {fname}")
            with col2:
                if st.button("‚ùå", key=f"hist_del_{i}"):
                    st.session_state.file_history.pop(i)
                    st.rerun()

# ---------------- Chat Area ----------------
st.title("üí¨ Chat v·ªõi t√†i li·ªáu")

# CSS custom cho chat gi·ªëng ChatGPT (gi·ªØ nguy√™n)
st.markdown("""
    <style>
    .stChatMessage.user {
        background-color: #d4f1ff !important;
        border-radius: 10px;
        padding: 8px;
    }
    .stChatMessage.assistant {
        background-color: #f1f1f1 !important;
        border-radius: 10px;
        padding: 8px;
    }
    .typing {
        display: inline-block;
        width: 1em;
        height: 1em;
        border-radius: 50%;
        background-color: #999;
        animation: blink 1.4s infinite both;
        margin: 0 2px;
    }
    @keyframes blink {
        0% { opacity: .2; }
        20% { opacity: 1; }
        100% { opacity: .2; }
    }
    </style>
""", unsafe_allow_html=True)

# Hi·ªÉn th·ªã l·ªãch s·ª≠ chat hi·ªán c√≥
chat_container = st.container()
with chat_container:
    for msg in st.session_state.history:
        with st.chat_message(msg["role"], avatar="üßë" if msg["role"] == "user" else "ü§ñ"):
            st.markdown(msg["content"])

# X·ª≠ l√Ω input ng∆∞·ªùi d√πng
if query := st.chat_input("Nh·∫≠p c√¢u h·ªèi..."):
    # 1) L∆∞u user message v√†o history + hi·ªÉn th·ªã ngay
    st.session_state.history.append({"role": "user", "content": query})
    with st.chat_message("user", avatar="üßë"):
        st.markdown(query)

    # 2) Hi·ªÉn th·ªã 1 √¥ assistant duy nh·∫•t l√†m placeholder typing
    with st.chat_message("assistant", avatar="ü§ñ"):
        typing_placeholder = st.empty()
        typing_placeholder.markdown(
            '<span class="typing"></span><span class="typing"></span><span class="typing"></span>',
            unsafe_allow_html=True
        )

        # 3) Chu·∫©n b·ªã danh s√°ch file ƒë√£ upload
        file_names = [f["name"] for f in st.session_state.files]
        # T√¨m file ƒë∆∞·ª£c nh·∫Øc trong query (so s√°nh c·∫£ t√™n ƒë·∫ßy ƒë·ªß v√† t√™n kh√¥ng m·ªü r·ªông)
        mentioned_files = []
        qlow = query.lower()
        for name in file_names:
            name_low = name.lower()
            name_noext = os.path.splitext(name_low)[0]
            if name_low in qlow or name_noext in qlow:
                mentioned_files.append(name)

        # N·∫øu c√≥ file ƒë∆∞·ª£c nh·∫Øc, ch·ªâ d√πng nh·ªØng file ƒë√≥; kh√¥ng th√¨ d√πng t·∫•t c·∫£
        if mentioned_files:
            target_files = [f for f in st.session_state.files if f["name"] in mentioned_files]
            reading_info = " ,".join(mentioned_files)
            # hi·ªÉn th·ªã th√¥ng tin nh·ªè trong main area (c√πng block assistant)
            typing_placeholder.markdown(f"üìñ Bot ƒëang ƒë·ªçc: **{reading_info}**<br><br>" +
                                       '<span class="typing"></span><span class="typing"></span><span class="typing"></span>',
                                       unsafe_allow_html=True)
        else:
            target_files = st.session_state.files[:]  # copy to√†n b·ªô
            typing_placeholder.markdown("üìñ Bot ƒëang ƒë·ªçc: **t·∫•t c·∫£ file ƒë√£ t·∫£i l√™n**<br><br>" +
                                       '<span class="typing"></span><span class="typing"></span><span class="typing"></span>',
                                       unsafe_allow_html=True)

        # 4) L·∫•y context t·ª´ c√°c target_files (ch·ªâ khi c√≥ db)
        context_parts = []
        for f in target_files:
            db = f.get("db")
            if not db:
                # N·∫øu file ch∆∞a c√≥ db (kho·∫£ng h·ª£p b·∫°n mu·ªën ch·ªâ l∆∞u l·ªãch s·ª≠), b·ªè qua
                continue
            try:
                # Ch·ªâ search n·∫øu query th·ª±c s·ª± c√≥ n·ªôi dung
                if query and query.strip():
                    results = db.similarity_search(query, k=2)
                    context_parts.extend([r.page_content for r in results if r and getattr(r, "page_content", None)])
            except Exception as e:
                # N·∫øu embed/search l·ªói, skip file n√†y (kh√¥ng crash app)
                # B·∫°n c√≥ th·ªÉ log l·ªói n·∫øu c·∫ßn: st.write(f"Search error for {f['name']}: {e}")
                continue

        context = "\n\n".join(context_parts).strip()

        # 5) N·∫øu kh√¥ng c√≥ context (ch∆∞a processed file n√†o), tr·∫£ l·ªùi h∆∞·ªõng d·∫´n
        if not context:
            reply = ("M√¨nh ch∆∞a t√¨m th·∫•y n·ªôi dung t·ª´ c√°c file ƒë√£ x·ª≠ l√Ω. "
                     "H√£y ƒë·∫£m b·∫£o b·∫°n ƒë√£ upload v√† file ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω (t·∫°o index) tr∆∞·ªõc khi h·ªèi, "
                     "ho·∫∑c g√µ r√µ 'ƒë·ªçc [t√™n file]' ƒë·ªÉ ch·ªâ ƒë·ªãnh file.")
            typing_placeholder.markdown(reply, unsafe_allow_html=True)
            st.session_state.history.append({"role": "assistant", "content": reply})
        else:
            # 6) G·ªçi model (b·ªçc try/except ƒë·ªÉ b·∫Øt l·ªói quota / network)
            prompt = f"Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n n·ªôi dung sau:\n\n{context}\n\nC√¢u h·ªèi: {query}"
            try:
                model = genai.GenerativeModel(CHAT_MODEL)
                response = model.generate_content(prompt)
                answer = response.text if hasattr(response, "text") else str(response)
            except Exception as e:
                # Hi·ªÉn th·ªã l·ªói th√¢n thi·ªán (v√≠ d·ª• quota)
                err_msg = f"‚ùå L·ªói khi g·ªçi API: {e}"
                typing_placeholder.markdown(err_msg, unsafe_allow_html=True)
                st.session_state.history.append({"role": "assistant", "content": err_msg})
            else:
                # 7) Thay typing b·∫±ng c√¢u tr·∫£ l·ªùi th·∫≠t (ghi v√†o history)
                typing_placeholder.markdown(answer, unsafe_allow_html=True)
                st.session_state.history.append({"role": "assistant", "content": answer})
                
# ---- T·∫£i v·ªÅ ƒëo·∫°n chat n·∫øu ng∆∞·ªùi d√πng y√™u c·∫ßu ----
if query is not None and any(kw in query.lower() for kw in ["t·∫£i v·ªÅ", "xu·∫•t file", "download"]):
    # x·ª≠ l√Ω t·∫£i v·ªÅ
    # Cho ph√©p ch·ªçn ƒë·ªãnh d·∫°ng
    export_format = st.radio("Ch·ªçn ƒë·ªãnh d·∫°ng t·∫£i v·ªÅ:", ["PDF", "DOCX", "TXT"], horizontal=True)

    if export_format == "PDF":
        from io import BytesIO
        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4)
        styles = getSampleStyleSheet()
        story = [Paragraph(answer, styles["Normal"])]
        doc.build(story)
        buffer.seek(0)
        st.download_button("‚¨áÔ∏è T·∫£i v·ªÅ PDF", data=buffer, file_name="chatbot_output.pdf", mime="application/pdf")

    elif export_format == "DOCX":
        from io import BytesIO
        from docx import Document
        doc = Document()
        doc.add_paragraph(answer)
        buffer = BytesIO()
        doc.save(buffer)
        buffer.seek(0)
        st.download_button("‚¨áÔ∏è T·∫£i v·ªÅ DOCX", data=buffer, file_name="chatbot_output.docx", mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document")

    elif export_format == "TXT":
        st.download_button("‚¨áÔ∏è T·∫£i v·ªÅ TXT", data=answer, file_name="chatbot_output.txt", mime="text/plain")
