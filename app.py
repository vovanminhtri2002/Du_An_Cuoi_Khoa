import streamlit as st
import os
import data_loader, vector_store
import google.generativeai as genai
from config import GEMINI_API_KEY, CHAT_MODEL
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, ListFlowable, ListItem
from reportlab.lib.styles import ParagraphStyle
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
import re
import shutil
from io import BytesIO

# ---------------- Fonts ----------------
pdfmetrics.registerFont(TTFont("DejaVuSans", "DejaVuSans.ttf"))

# ---------------- Config ----------------
genai.configure(api_key=GEMINI_API_KEY)
st.set_page_config(page_title="Chat v·ªõi t√†i li·ªáu", layout="wide")
TEMP_DIR = "temp_uploads"
os.makedirs(TEMP_DIR, exist_ok=True)

# ---------------- Session state ----------------
if "history" not in st.session_state:
    st.session_state.history = []
if "files" not in st.session_state:
    st.session_state.files = {}

# ---------------- Helper delete ----------------
def delete_file(fname):
    file_data = st.session_state.files.get(fname)
    if file_data:
        # Xo√° file t·∫°m
        if os.path.exists(file_data["path"]):
            os.remove(file_data["path"])
        # Xo√° folder FAISS
        file_base = os.path.splitext(fname)[0]
        safe_name = re.sub(r'[^a-zA-Z0-9_-]', '_', file_base)
        faiss_folder = os.path.join(vector_store.FAISS_DIR, safe_name)
        if os.path.exists(faiss_folder):
            shutil.rmtree(faiss_folder)
        # Xo√° kh·ªèi session
        if fname in st.session_state.files:
            del st.session_state.files[fname]
        st.experimental_rerun()

# ---------------- Sidebar ----------------
with st.sidebar:
    st.header("üìÇ T√†i li·ªáu c·ªßa b·∫°n")
    uploaded_files = st.file_uploader(
        "T·∫£i file (PDF, Word, Excel, ·∫¢nh)...",
        type=["pdf", "docx", "xlsx", "png", "jpg", "jpeg"],
        accept_multiple_files=True
    )

    if uploaded_files:
        for file in uploaded_files:
            if file.name in st.session_state.files:
                continue
            # L∆∞u file t·∫°m
            temp_path = os.path.join(TEMP_DIR, file.name)
            with open(temp_path, "wb") as f:
                f.write(file.read())
            # ƒê·ªçc n·ªôi dung
            text = data_loader.load_file(temp_path)
            chunks = vector_store.get_text_chunks(text)
            # sanitize t√™n file, b·ªè extension v√† ch·ªâ c√≤n a-z, A-Z, 0-9, _,-
            file_base = os.path.splitext(file.name)[0]
            safe_name = re.sub(r'[^a-zA-Z0-9_-]', '_', file_base)
            db_path = os.path.join(vector_store.FAISS_DIR, safe_name)
            os.makedirs(db_path, exist_ok=True)
            # l∆∞u FAISS index
            vector_store.save_vector_store(chunks, save_path=db_path)
            # load FAISS
            db = vector_store.load_vector_store(db_path)
            # l∆∞u v√†o session
            st.session_state.files[file.name] = {
                "file_obj": file,
                "path": temp_path,
                "text": text,
                "db": db,
                "db_path": db_path
            }

    # Hi·ªÉn th·ªã file ch√≠nh th·ª©c
    st.subheader("üìå File ƒëang s·ª≠ d·ª•ng:")
    for fname in list(st.session_state.files.keys()):
        col1, col2 = st.columns([4,1])
        col1.write(fname)
        if col2.button("‚ùå", key=f"remove_active_{fname}"):
            delete_file(fname)
            st.experimental_rerun()

    # L·ªãch s·ª≠ t·∫£i file
    st.subheader("üïë L·ªãch s·ª≠ t·∫£i file:")
    for fname in list(st.session_state.files.keys()):
        col1, col2 = st.columns([4,1])
        col1.write(fname)
        if col2.button("‚ùå", key=f"remove_history_{fname}"):
            delete_file(fname)
            st.experimental_rerun()

# ---------------- Chat area ----------------
st.title("üí¨ Chat v·ªõi t√†i li·ªáu")

st.markdown("""
<style>
.stChatMessage.user {background-color: #d4f1ff !important; border-radius: 10px; padding: 8px;}
.stChatMessage.assistant {background-color: #f1f1f1 !important; border-radius: 10px; padding: 8px;}
.typing {display:inline-block; width:1em; height:1em; border-radius:50%; background-color:#999; animation: blink 1.4s infinite both; margin:0 2px;}
@keyframes blink {0% {opacity:.2;} 20% {opacity:1;} 100% {opacity:.2;}}
</style>
""", unsafe_allow_html=True)

chat_container = st.container()
with chat_container:
    for msg in st.session_state.history:
        with st.chat_message(msg["role"], avatar="üßë" if msg["role"]=="user" else "ü§ñ"):
            st.markdown(msg["content"])

# Input
if query := st.chat_input("Nh·∫≠p c√¢u h·ªèi..."):
    st.session_state.history.append({"role":"user","content":query})
    with st.chat_message("user", avatar="üßë"):
        st.markdown(query)
    with st.chat_message("assistant", avatar="ü§ñ") as msg:
        typing_placeholder = st.empty()
        typing_placeholder.markdown('<span class="typing"></span>'*3, unsafe_allow_html=True)
        # ch·ªçn target files
        file_names = [f for f in st.session_state.files.keys()]
        mentioned_files = []
        qlow = query.lower()
        for name in file_names:
            name_low = name.lower()
            name_noext = os.path.splitext(name_low)[0]
            if name_low in qlow or name_noext in qlow:
                mentioned_files.append(name)
        if mentioned_files:
            target_files = [st.session_state.files[n] for n in mentioned_files]
            reading_info = ", ".join(mentioned_files)
            typing_placeholder.markdown(f"üìñ Bot ƒëang ƒë·ªçc: **{reading_info}**<br><br>"+'<span class="typing"></span>'*3, unsafe_allow_html=True)
        else:
            target_files = list(st.session_state.files.values())
            typing_placeholder.markdown("üìñ Bot ƒëang ƒë·ªçc: **t·∫•t c·∫£ file ƒë√£ t·∫£i l√™n**<br><br>"+'<span class="typing"></span>'*3, unsafe_allow_html=True)
        # L·∫•y context
        context_parts = []
        for f in target_files:
            db = f.get("db")
            if not db: continue
            try:
                results = db.similarity_search(query, k=2)
                context_parts.extend([r.page_content for r in results if r and getattr(r,"page_content",None)])
            except: continue
        context = "\n\n".join(context_parts).strip()
        if not context:
            reply = "M√¨nh ch∆∞a t√¨m th·∫•y n·ªôi dung t·ª´ c√°c file ƒë√£ x·ª≠ l√Ω. H√£y ƒë·∫£m b·∫£o ƒë√£ upload v√† t·∫°o index tr∆∞·ªõc khi h·ªèi."
            typing_placeholder.markdown(reply, unsafe_allow_html=True)
            st.session_state.history.append({"role":"assistant","content":reply})
            st.session_state.last_answer = reply
        else:
            prompt = f"Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n n·ªôi dung sau:\n\n{context}\n\nC√¢u h·ªèi: {query}"
            try:
                model = genai.GenerativeModel(CHAT_MODEL)
                response = model.generate_content(prompt)
                answer = response.text if hasattr(response,"text") else str(response)
            except Exception as e:
                err_msg = f"‚ùå L·ªói khi g·ªçi API: {e}"
                typing_placeholder.markdown(err_msg, unsafe_allow_html=True)
                st.session_state.history.append({"role":"assistant","content":err_msg})
            else:
                typing_placeholder.markdown(answer, unsafe_allow_html=True)
                st.session_state.history.append({"role":"assistant","content":answer})
                st.session_state.last_answer = answer

# ---------------- Export ----------------
def _clean_text_for_plain(s: str) -> str:
    if s is None: return ""
    s = s.strip()
    s = re.sub(r'^[\u2022\*\-\s]+', '', s)
    s = re.sub(r'\*\*(.+?)\*\*', r'\1', s)
    s = re.sub(r'(?<!\*)\*(?!\*)(.+?)(?<!\*)\*(?!\*)', r'\1', s)
    s = re.sub(r':\*+', ':', s)
    return s

def _clean_text_for_pdf_html(s: str) -> str:
    if s is None: return ""
    s = s.strip()
    s = re.sub(r'^[\u2022\*\-\s]+', '', s)
    s = re.sub(r'\*\*(.+?)\*\*', r'<b>\1</b>', s)
    s = re.sub(r'(?<!\*)\*(?!\*)(.+?)(?<!\*)\*(?!\*)', r'<i>\1</i>', s)
    s = re.sub(r':\*+', ':', s)
    return s

if "last_answer" in st.session_state and st.session_state.last_answer:
    st.markdown("### üì• T·∫£i v·ªÅ c√¢u tr·∫£ l·ªùi g·∫ßn nh·∫•t:")
    export_format = st.radio("Ch·ªçn ƒë·ªãnh d·∫°ng:", ["PDF","DOCX","TXT","Excel (code)"], horizontal=True)

    if export_format == "PDF":
        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4)
        style = ParagraphStyle(name="Vietnamese", fontName="DejaVuSans", fontSize=11, leading=15, spaceAfter=8)
        story = []
        raw_lines = st.session_state.last_answer.splitlines()
        bullets = []
        for raw in raw_lines:
            line = raw.strip()
            if not line:
                if bullets:
                    story.append(ListFlowable([ListItem(Paragraph(b,style)) for b in bullets], bulletType="bullet"))
                    bullets=[]
                story.append(Spacer(1,8))
                continue
            if re.match(r'^[\u2022\*\-\s]+', raw) or re.match(r'^\d+\.\s', line):
                bullets.append(_clean_text_for_pdf_html(raw))
                continue
            if bullets:
                story.append(ListFlowable([ListItem(Paragraph(b,style)) for b in bullets], bulletType="bullet"))
                bullets=[]
            story.append(Paragraph(_clean_text_for_pdf_html(line), style))
        if bullets:
            story.append(ListFlowable([ListItem(Paragraph(b,style)) for b in bullets], bulletType="bullet"))
        doc.build(story)
        buffer.seek(0)
        st.download_button("‚¨áÔ∏è T·∫£i v·ªÅ PDF", data=buffer, file_name="chatbot_output.pdf", mime="application/pdf")

    elif export_format == "DOCX":
        from docx import Document
        buffer = BytesIO()
        doc = Document()
        def _add_docx_paragraph_with_md_runs(paragraph_obj, text):
            tokens = re.split(r'(\*\*.*?\*\*|\*.*?\*)', text)
            for tok in tokens:
                if not tok: continue
                if tok.startswith("**") and tok.endswith("**") and len(tok)>=4:
                    run = paragraph_obj.add_run(tok[2:-2]); run.bold=True
                elif tok.startswith("*") and tok.endswith("*") and len(tok)>=2:
                    run = paragraph_obj.add_run(tok[1:-1]); run.italic=True
                else:
                    paragraph_obj.add_run(tok)
        for raw in st.session_state.last_answer.splitlines():
            line = raw.strip()
            if not line:
                doc.add_paragraph(""); continue
            if re.match(r'^[\u2022\*\-\s]+', raw):
                p = doc.add_paragraph(style="List Bullet"); _add_docx_paragraph_with_md_runs(p,_clean_text_for_plain(raw)); continue
            if re.match(r'^\d+\.\s', line):
                p = doc.add_paragraph(style="List Number"); _add_docx_paragraph_with_md_runs(p,_clean_text_for_plain(line)); continue
            p = doc.add_paragraph(); _add_docx_paragraph_with_md_runs(p,_clean_text_for_plain(line))
        doc.save(buffer); buffer.seek(0)
        st.download_button("‚¨áÔ∏è T·∫£i v·ªÅ DOCX", data=buffer, file_name="chatbot_output.docx", mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document")

    elif export_format == "TXT":
        cleaned_lines = [_clean_text_for_plain(l) if l.strip() else "" for l in st.session_state.last_answer.splitlines()]
        st.download_button("‚¨áÔ∏è T·∫£i v·ªÅ TXT", data="\n".join(cleaned_lines), file_name="chatbot_output.txt", mime="text/plain")

    elif export_format == "Excel (code)":
        st.markdown("### üí° G·ª£i √Ω code ƒë·ªÉ xu·∫•t ra Excel (ch·∫°y local)")
        example_code = f'''
import pandas as pd
lines = [line.strip() for line in """{st.session_state.last_answer}""".split("\\n") if line.strip()]
df = pd.DataFrame({{"N·ªôi dung": lines}})
df.to_excel("chatbot_output.xlsx", index=False, sheet_name="Chatbot Output")
print("‚úÖ ƒê√£ l∆∞u chatbot_output.xlsx")
        '''
        st.code(example_code, language="python")